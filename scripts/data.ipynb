{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fd5fa2",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb7e5c-6f9d-4ab1-9b43-40c756b66ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, quote\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def parse_markdown_to_csv(md_content, csv_file_path):\n",
    "    heading_pattern = re.compile(r'^(#+)\\s*(.*)', re.MULTILINE)\n",
    "    headings_contents = []\n",
    "    current_heading = None\n",
    "    current_content = []\n",
    "    \n",
    "    for line in md_content.split('\\n'):\n",
    "        match = heading_pattern.match(line)\n",
    "        if match:\n",
    "            if current_heading is not None:\n",
    "                headings_contents.append([current_heading, ' '.join(current_content).strip()])\n",
    "            current_heading = match.group(2).strip()\n",
    "            current_content = []\n",
    "        else:\n",
    "            if line.strip():\n",
    "                current_content.append(line.strip())\n",
    "    \n",
    "    if current_heading is not None:\n",
    "        headings_contents.append([current_heading, ' '.join(current_content).strip()])\n",
    "    \n",
    "    df = pd.DataFrame(headings_contents, columns=['Title', 'Content'])\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "def fetch_and_convert_readme_to_csv(repo_urls, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # GitHub API endpoint for fetching the contents of the README file\n",
    "    for url in repo_urls:\n",
    "        parsed_url = urlparse(url)\n",
    "        parts = parsed_url.path.strip('/').split('/')\n",
    "        repo_user, repo_name = parts[0], parts[1]\n",
    "        api_url = f\"https://api.github.com/repos/{repo_user}/{repo_name}/readme\"\n",
    "        \n",
    "        # Set up appropriate headers for GitHub API including the token for authorization\n",
    "        headers = {\n",
    "            'Accept': 'application/vnd.github.v3.raw',\n",
    "            'Authorization': 'YOUR_GITHUB_TOKEN'  # Replace 'YOUR_GITHUB_TOKEN' with your actual GitHub token\n",
    "        }\n",
    "        \n",
    "        response = requests.get(api_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            readme_content = response.text\n",
    "            csv_file_path = os.path.join(output_dir, f\"{repo_name}.csv\")\n",
    "            parse_markdown_to_csv(readme_content, csv_file_path)\n",
    "            print(f\"Processed {repo_name}.csv\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch README for {repo_name}: {response.status_code}\")\n",
    "\n",
    "# Example usage:\n",
    "repo_urls = [\n",
    "    'https://github.com/context-labs/autodoc'\n",
    "]\n",
    "\n",
    "fetch_and_convert_readme_to_csv(repo_urls, 'output_csv_files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d005ac-8225-4d78-8650-09b98ff4ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import base64\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def fetch_and_concatenate_source_code(repo_urls, output_dir, token):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'token {token}',\n",
    "        'Accept': 'application/vnd.github.v3.raw'  # Requests raw content directly\n",
    "    }\n",
    "\n",
    "    for url in repo_urls:\n",
    "        parsed_url = urlparse(url)\n",
    "        parts = parsed_url.path.strip('/').split('/')\n",
    "        repo_user, repo_name = parts[0], parts[1]\n",
    "\n",
    "        # Fetch the default branch\n",
    "        repo_info_url = f'https://api.github.com/repos/{repo_user}/{repo_name}'\n",
    "        repo_info_response = requests.get(repo_info_url, headers=headers)\n",
    "        if repo_info_response.status_code == 200:\n",
    "            default_branch = repo_info_response.json()['default_branch']\n",
    "        else:\n",
    "            print(f'Failed to fetch repo info for {repo_name}: {repo_info_response.status_code}')\n",
    "            continue\n",
    "\n",
    "        api_url = f'https://api.github.com/repos/{repo_user}/{repo_name}/git/trees/{default_branch}?recursive=true'\n",
    "        response = requests.get(api_url, headers={'Authorization': f'token {token}', 'Accept': 'application/vnd.github.v3+json'})\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            all_files_content = []\n",
    "\n",
    "            for file in data['tree']:\n",
    "                if file['type'] == 'blob' and file['path'].endswith(('.py', '.c', '.cpp', '.java', '.js', '.ts', '.go')):\n",
    "                    file_url = f\"https://api.github.com/repos/{repo_user}/{repo_name}/contents/{file['path']}?ref={default_branch}\"\n",
    "                    file_response = requests.get(file_url, headers=headers)\n",
    "                    if file_response.status_code == 200:\n",
    "                        file_content = file_response.text\n",
    "                        all_files_content.append(file_content)\n",
    "\n",
    "            concatenated_content = \"\\n\".join(all_files_content)\n",
    "            df = pd.DataFrame([concatenated_content], columns=['SourceCode'])\n",
    "            df.to_csv(os.path.join(output_dir, f'{repo_name}_context.csv'), index=False)\n",
    "            print(f'Saved {repo_name}_context.csv')\n",
    "        else:\n",
    "            print(f'Failed to fetch repository data for {repo_name}: {response.status_code}')\n",
    "\n",
    "# Example usage:\n",
    "repo_urls = [\n",
    "    \"https://github.com/context-labs/autodoc\"\n",
    "]\n",
    "output_directory = 'output_csv_files'\n",
    "github_token = 'YOUR_GITHUB_TOKEN'  # Replace with your GitHub access token\n",
    "\n",
    "fetch_and_concatenate_source_code(repo_urls, output_directory, github_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e78d0b1-b921-468b-8376-d3651bd2d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, quote\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "# Clone repository to a local path\n",
    "def git_clone(repo_url, clone_path):\n",
    "    if os.path.exists(clone_path):\n",
    "        subprocess.run(['rm', '-rf', clone_path], check=True)\n",
    "    subprocess.run(['git', 'clone', repo_url, clone_path], check=True)\n",
    "\n",
    "# Parse the README.md content into a CSV\n",
    "def parse_markdown_to_csv(md_file_path, csv_file_path):\n",
    "    with open(md_file_path, 'r', encoding='utf-8') as file:\n",
    "        md_content = file.read()\n",
    "\n",
    "    heading_pattern = re.compile(r'^(#+)\\s*(.*)', re.MULTILINE)\n",
    "    headings_contents = []\n",
    "    current_heading = None\n",
    "    current_content = []\n",
    "\n",
    "    for line in md_content.split('\\n'):\n",
    "        match = heading_pattern.match(line)\n",
    "        if match:\n",
    "            if current_heading is not None:\n",
    "                headings_contents.append([current_heading, ' '.join(current_content).strip()])\n",
    "            current_heading = match.group(2).strip()\n",
    "            current_content = []\n",
    "        else:\n",
    "            if line.strip():\n",
    "                current_content.append(line.strip())\n",
    "\n",
    "    if current_heading is not None:\n",
    "        headings_contents.append([current_heading, ' '.join(current_content).strip()])\n",
    "\n",
    "    df = pd.DataFrame(headings_contents, columns=['Title', 'Content'])\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "# Process a list of GitHub repository URLs\n",
    "def process_repos(repo_urls, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for url in repo_urls:\n",
    "        parsed_url = urlparse(url)\n",
    "        parts = parsed_url.path.strip('/').split('/')\n",
    "        repo_user, repo_name = parts[0], parts[1]\n",
    "        clone_path = f\"/tmp/{repo_name}\"  # Temporary path for cloning\n",
    "        git_clone(url, clone_path)\n",
    "\n",
    "        readme_path = os.path.join(clone_path, 'README.md')\n",
    "        csv_file_path = os.path.join(output_dir, f\"{repo_name}.csv\")\n",
    "        if os.path.exists(readme_path):\n",
    "            parse_markdown_to_csv(readme_path, csv_file_path)\n",
    "            print(f\"Processed {repo_name}.csv\")\n",
    "        else:\n",
    "            print(f\"README.md not found for {repo_name}\")\n",
    "\n",
    "        # Remove the repository directory to clean up\n",
    "        subprocess.run(['rm', '-rf', clone_path], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f50bec-95dd-4f3d-85da-6d60768cea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this list with your own list of 300 URLs\n",
    "repo_urls = []\n",
    "output_directory = 'output_csv_files'\n",
    "process_repos(repo_urls, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f96d8c-589b-446b-bceb-63f4fa4b9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f62fd8-1e33-4250-8c9a-f14d5d9cdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clone a GitHub repository and collect all source code into a single string\n",
    "def collect_source_code(repo_url):\n",
    "    # Extract the repo name from the URL\n",
    "    repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "    subprocess.run(['git', 'clone', repo_url], check=True)\n",
    "    \n",
    "    # Collect all source code files into a single string\n",
    "    source_code = []\n",
    "    for root, dirs, files in os.walk(repo_name):\n",
    "        for file in files:\n",
    "            # Filter for source code files only (adjust filters as needed)\n",
    "            if file.endswith(('.py', '.js', '.java', '.cpp', '.c', '.h', '.html', '.css', '.ts', '.go', '.rb', '.php')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', errors='ignore') as f:\n",
    "                    source_code.append(f.read())\n",
    "                    \n",
    "    # Join all source code files as one big string\n",
    "    concatenated_code = \"\\n\".join(source_code)\n",
    "    \n",
    "    # Delete the repo after extraction\n",
    "    shutil.rmtree(repo_name)\n",
    "    \n",
    "    return repo_name, concatenated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca9c11-5104-4102-bfd4-607705f3aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store CSV files\n",
    "output_dir = \"github_repo_source_code\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a CSV file per GitHub repo\n",
    "for url in github_urls:\n",
    "    try:\n",
    "        repo_name, concatenated_code = collect_source_code(url)\n",
    "        csv_file_name = f\"{repo_name}.csv\"\n",
    "        csv_file_path = os.path.join(output_dir, csv_file_name)\n",
    "        with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow([concatenated_code])\n",
    "        print(f\"Successfully processed and saved {url} to {csv_file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "\n",
    "print(\"All repositories processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f097f-1bb8-43ec-9d45-ce799b9dc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, quote\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Function to clone a GitHub repository and collect all source code into a single string\n",
    "def collect_source_code(repo_url):\n",
    "    # Extract the repo name from the URL\n",
    "    repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "    subprocess.run(['git', 'clone', repo_url], check=True)\n",
    "    \n",
    "    # Collect all source code files into a single string\n",
    "    source_code = []\n",
    "    for root, dirs, files in os.walk(repo_name):\n",
    "        for file in files:\n",
    "            # Filter for source code files only (adjust filters as needed)\n",
    "            if file.endswith(('.py', '.js', '.java', '.cpp', '.c', '.h', '.html', '.css', '.ts', '.go', '.rb', '.php')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', errors='ignore') as f:\n",
    "                    source_code.append(f.read())\n",
    "                    \n",
    "    # Join all source code files as one big string\n",
    "    concatenated_code = \"\\n\".join(source_code)\n",
    "    print(type(concatenated_code))\n",
    "    \n",
    "    # Delete the repo after extraction\n",
    "    shutil.rmtree(repo_name)\n",
    "    \n",
    "    return repo_name, concatenated_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d9f1f-de7c-4de6-a4d5-605cbda7875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store CSV files\n",
    "output_dir = \"github_repo_source_code\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for url in github_urls:\n",
    "    try:\n",
    "        repo_name, concatenated_code = collect_source_code(url)\n",
    "        txt_file_name = f\"{repo_name}.txt\"\n",
    "        txt_file_name = os.path.join(output_dir, txt_file_name)\n",
    "        with open(txt_file_name, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(concatenated_code)\n",
    "        print(f\"Successfully processed and saved {url} to {txt_file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "\n",
    "print(\"All repositories processed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2313a",
   "metadata": {},
   "source": [
    "# HNSWLIB Context Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hnswlib sentence_transformers langchain_text_splitters langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "\n",
    "def get_context(sentences, embeds, question_embed):\n",
    "    dim = embeds.shape[1]\n",
    "    num_elements = embeds.shape[0]\n",
    "\n",
    "    # Generating sample data\n",
    "    data = embeds\n",
    "    ids = np.arange(num_elements)\n",
    "\n",
    "    # Declaring index\n",
    "    p = hnswlib.Index(space = 'cosine', dim = dim) # possible options are l2, cosine or ip\n",
    "\n",
    "    # Initializing index - the maximum number of elements should be known beforehand\n",
    "    p.init_index(max_elements = num_elements, ef_construction = 200, M = 16)\n",
    "\n",
    "    # Element insertion (can be called several times):\n",
    "    p.add_items(data, ids)\n",
    "\n",
    "    # Controlling the recall by setting ef:\n",
    "    p.set_ef(50) # ef should always be > k\n",
    "\n",
    "    # Query dataset, k - number of the closest elements (returns 2 numpy arrays)\n",
    "    labels, distances = p.knn_query(question_embed, k = 4)\n",
    "\n",
    "    return \"\".join([sentences[index] for index in labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c04ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device = 'cuda:0')\n",
    "\n",
    "root_dir = \"./\"\n",
    "context_root_dir = \"./github_repo_source_code/\"\n",
    "readme_root_dir = \"./output_csv_files/\"\n",
    "\n",
    "with open('./repo_urls.pickle', 'rb') as f:\n",
    "    repo_name_list = pickle.load(f)\n",
    "\n",
    "new_rows = []\n",
    "for repo in repo_name_list:\n",
    "    repo_name = repo.split(\"/\")[-1]\n",
    "    file1 = repo_name +\".txt\"\n",
    "    with open(os.path.join(context_root_dir, file1)) as f:\n",
    "        data = f.read()\n",
    "    sentences = text_splitter.split_text(data)\n",
    "    embeddings = model.encode(sentences)\n",
    "    print(embeddings.shape)\n",
    "\n",
    "    file2 = repo_name +\".csv\"\n",
    "    df2 = pd.read_csv(os.path.join(readme_root_dir, file2))\n",
    "    for i, row in df2.iterrows():\n",
    "        title = row[\"Title\"]\n",
    "        content = row[\"Content\"]\n",
    "        if \"?\" in title:\n",
    "            question = f\"In context to the project {repo_name}, answer the following. \" + title\n",
    "            question_embedding = model.encode([question])\n",
    "            context = get_context(sentences, embeddings, question_embedding)\n",
    "            new_row  = {\"Question\": question, \"Context\": context, \"Answer\": content, \"Repo Url\": repo, \"Repo\": repo_name}\n",
    "            new_rows.append(new_row)\n",
    "        else:\n",
    "            question = f\"Provide the README content for the section with heading \\\"{title}\\\" starting with ## {title}.\"\n",
    "            question_embedding = model.encode([question])\n",
    "            context = get_context(sentences, embeddings, question_embedding)\n",
    "            new_row  = {\"Question\": question, \"Context\": context, \"Answer\": content, \"Repo Url\": repo, \"Repo\": repo_name}\n",
    "            new_rows.append(new_row)\n",
    "    print(len(new_rows))\n",
    "    df3 = pd.DataFrame(new_rows, index=None)\n",
    "    df3.to_csv(os.path.join(root_dir, \"readme_qa.csv\"), mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7595e4",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62492c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "  \"\"\"Remove URLs from a given text string.\"\"\"\n",
    "  url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "  return re.sub(url_pattern, '', text)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "  \"\"\"Remove HTML tags from a given text string.\"\"\"\n",
    "  html_pattern = r'<.*?>'\n",
    "  return re.sub(html_pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ef45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Define the regular expression pattern for HTTP URLs\n",
    "    http_pattern = re.compile(r'http://[^\\s]+')\n",
    "    # Remove HTTP URLs\n",
    "    text = http_pattern.sub('', str(text))\n",
    "\n",
    "    https_pattern = re.compile(r'https://[^\\s]+')\n",
    "    # Remove HTTPS URLs\n",
    "    text = https_pattern.sub('', str(text))\n",
    "    \n",
    "    # Define the regular expression pattern for <img> tags\n",
    "    img_pattern = re.compile(r'<img[^>]*>')\n",
    "    # Remove <img> tags\n",
    "    text = img_pattern.sub('', str(text))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8cc5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_emoji(tx):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', tx)\n",
    "\n",
    "def text_cleaner(tx):\n",
    "\n",
    "    text = re.sub(r\"won\\'t\", \"would not\", tx)\n",
    "    text = re.sub(r\"im\", \"i am\", tx)\n",
    "    text = re.sub(r\"Im\", \"I am\", tx)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"don\\'t\", \"do not\", text)\n",
    "    text = re.sub(r\"shouldn\\'t\", \"should not\", text)\n",
    "    text = re.sub(r\"needn\\'t\", \"need not\", text)\n",
    "    text = re.sub(r\"hasn\\'t\", \"has not\", text)\n",
    "    text = re.sub(r\"haven\\'t\", \"have not\", text)\n",
    "    text = re.sub(r\"weren\\'t\", \"were not\", text)\n",
    "    text = re.sub(r\"mightn\\'t\", \"might not\", text)\n",
    "    text = re.sub(r\"didn\\'t\", \"did not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    # text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'https?://[^\\s\\\")]+', '', text)\n",
    "    text = re.sub(r'http?://[^\\s\\\")]+', '', text)\n",
    "    text = re.sub(r'http%3A%2F%2F[^\\s\\\")]+', '', text)\n",
    "    text = re.sub(r'https%3A%2F%2F[^\\s\\\")]+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\!\\?\\.\\@]',' ' , text)\n",
    "    text = re.sub(r'[!]+' , '!' , text)\n",
    "    text = re.sub(r'[?]+' , '?' , text)\n",
    "    text = re.sub(r'[.]+' , '.' , text)\n",
    "    text = re.sub(r'[@]+' , '@' , text)\n",
    "    text = re.sub(r'unk' , '<UNK>' , text)\n",
    "    # text = re.sub('\\n', '<NL>', text)\n",
    "    # text = re.sub('\\t', '<TAB>', text)\n",
    "    # text = re.sub(r'\\s+', '<SP>', text)\n",
    "    # text = re.sub(r'(<img[^>]*\\bsrc=\")[^\"]*(\")', '<img src=<IMG_SRC>', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[ ]+' , ' ' , text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb59731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"readme_qa.csv\")\n",
    "df.columns = [str(q).strip() for q in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5a290e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Provide the README content for the section with heading \"Try Public APIs for free\" starting with ## Try Public APIs for free.',\n",
       "       'Provide the README content for the section with heading \"APILayer APIs\" starting with ## APILayer APIs.',\n",
       "       'Provide the README content for the section with heading \"Popular APIs\" starting with ## Popular APIs.',\n",
       "       'Provide the README content for the section with heading \"Popular categories\" starting with ## Popular categories.',\n",
       "       'Provide the README content for the section with heading \"Learn more about Public APIs\" starting with ## Learn more about Public APIs.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Question\"].values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9986405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Explore popular APIs and see them work in Postman. <br > <p> <a href=\"https://apilayer.com\"> <div> <img src=\".github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png\" width=\"250\" alt=\"APILayer Logo\" /> </div> </a> </p> [APILayer](https://apilayer.com/) is the fastest way to integrate APIs into any product. They created this repository to support the community in easily finding public APIs. Explore their collections on the [Postman API Network](https://www.postman.com/apilayer/workspace/apilayer/overview).',\n",
       "       '| API | Description | Call this API | |:---|:---|:---| | [IP Stack](https://ipstack.com/) | Locate and Identify Website Visitors by IP Address | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)| | [Marketstack](https://marketstack.com/) | Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)| | [Weatherstack](https://weatherstack.com/) | Retrieve instant, accurate weather information for any location in the world in lightweight JSON format | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)| | [Numverify](https://numverify.com/) | Global Phone Number Validation & Lookup JSON API |[<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)| | [Fixer](https://fixer.io/) | Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates. |[<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)| <br >',\n",
       "       '| API | Description | Auth | Call this API | |:---|:---|:---|:---| | [HTTP Cat](https://http.cat/) | Cat for every HTTP Status | No | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/25426789-12bc9867-e424-4de8-b4ee-662632714f6c?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D25426789-12bc9867-e424-4de8-b4ee-662632714f6c%26entityType%3Dcollection%26workspaceId%3De4d9a7d3-b961-474e-a054-51861ed481f6) | | [Sportmonks Football](https://docs.sportmonks.com/football/) | Football score/schedule, news API, tv channels, stats, history, display standing e.g. epl, la liga | `apiKey` | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/25426789-b21c360e-6b87-431d-9b39-74e824f29e45?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D25426789-b21c360e-6b87-431d-9b39-74e824f29e45%26entityType%3Dcollection%26workspaceId%3De4d9a7d3-b961-474e-a054-51861ed481f6)| | [Google Maps](https://developers.notion.com) | Create/customize digital maps based on Google Maps data | `apiKey`  | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/25426789-2c9bbe63-f45b-45d4-9327-ec3376542b64?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D25426789-2c9bbe63-f45b-45d4-9327-ec3376542b64%26entityType%3Dcollection%26workspaceId%3De4d9a7d3-b961-474e-a054-51861ed481f6)| | [Notion](https://developers.notion.com) | Integrate with Notion | `apiKey`  | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/25426789-68f0e9e4-b7bc-4543-945a-b50ae385c540?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D25426789-68f0e9e4-b7bc-4543-945a-b50ae385c540%26entityType%3Dcollection%26workspaceId%3De4d9a7d3-b961-474e-a054-51861ed481f6)| | [Plaid](https://www.plaid.com/docs) | Connect with user\\'s bank accounts and access transaction data\\t | `apiKey` | [<img src=\"https://run.pstmn.io/button.svg\" alt=\"Run In Postman\" style=\"width: 128px; height: 32px;\">](https://god.gw.postman.com/run-collection/25426789-ae5e66eb-613e-4553-a99c-0f58d875ff88?action=collection%2Ffork&source=rip_markdown&collection-url=entityId%3D25426789-ae5e66eb-613e-4553-a99c-0f58d875ff88%26entityType%3Dcollection%26workspaceId%3De4d9a7d3-b961-474e-a054-51861ed481f6)| <br >',\n",
       "       '* [Animals](#animals) * [Anime](#anime) * [Art & Design](#art--design) * [Authentication & Authorization](#authentication--authorization) * [Blockchain](#blockchain) * [Business](#business) * [Currency Exchange](#currency-exchange) * [Social](#social) <br >',\n",
       "       '<br > <strong>Get Involved</strong> * [Contributing Guide](CONTRIBUTING.md) * [API for this project](https://github.com/davemachado/public-api) * [Issues](https://github.com/public-apis/public-apis/issues) * [Pull Requests](https://github.com/public-apis/public-apis/pulls) * [LICENSE](LICENSE) Own an API? Publish your own [Run in Postman](https://learning.postman.com/docs/collaborating-in-postman/public-api-network/public-api-network-overview/) button. <br /> <strong>More Resources</strong> * [Postman API Network](https://postman.com/explore) * [Free APIs](https://free-apis.github.io) * [Dev Resources](https://devresourc.es/tools-and-utilities/public-apis) * [Apihouse](https://apihouse.vercel.app) * [Collective APIs](https://collective-api.vercel.app) </div> </details> <br /> <br />'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Answer\"].values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4debc9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Repo Url</th>\n",
       "      <th>Repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>Explore popular APIs and see them work in Post...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>| API | Description | Call this API | |:---|:-...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>| API | Description | Auth | Call this API | |...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td># check each category for the minimum number o...</td>\n",
       "      <td>* [Animals](#animals) * [Anime](#anime) * [Art...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>&lt;br &gt; &lt;strong&gt;Get Involved&lt;/strong&gt; * [Contrib...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Question  \\\n",
       "0         0.0  Provide the README content for the section wit...   \n",
       "1         1.0  Provide the README content for the section wit...   \n",
       "2         2.0  Provide the README content for the section wit...   \n",
       "3         3.0  Provide the README content for the section wit...   \n",
       "4         4.0  Provide the README content for the section wit...   \n",
       "\n",
       "                                             Context  \\\n",
       "0  Discussions in issues and pull requests:\\n    ...   \n",
       "1  Discussions in issues and pull requests:\\n    ...   \n",
       "2  Discussions in issues and pull requests:\\n    ...   \n",
       "3  # check each category for the minimum number o...   \n",
       "4  Discussions in issues and pull requests:\\n    ...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Explore popular APIs and see them work in Post...   \n",
       "1  | API | Description | Call this API | |:---|:-...   \n",
       "2  | API | Description | Auth | Call this API | |...   \n",
       "3  * [Animals](#animals) * [Anime](#anime) * [Art...   \n",
       "4  <br > <strong>Get Involved</strong> * [Contrib...   \n",
       "\n",
       "                                     Repo Url         Repo  \n",
       "0  https://github.com/public-apis/public-apis  public-apis  \n",
       "1  https://github.com/public-apis/public-apis  public-apis  \n",
       "2  https://github.com/public-apis/public-apis  public-apis  \n",
       "3  https://github.com/public-apis/public-apis  public-apis  \n",
       "4  https://github.com/public-apis/public-apis  public-apis  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea28b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Repo Url</th>\n",
       "      <th>Repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>Explore popular APIs and see them work in Post...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>| API | Description | Call this API | |:---|:-...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>| API | Description | Auth | Call this API | |...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td># check each category for the minimum number o...</td>\n",
       "      <td>* [Animals](#animals) * [Anime](#anime) * [Art...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>&lt;br &gt; &lt;strong&gt;Get Involved&lt;/strong&gt; * [Contrib...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Provide the README content for the section wit...   \n",
       "1  Provide the README content for the section wit...   \n",
       "2  Provide the README content for the section wit...   \n",
       "3  Provide the README content for the section wit...   \n",
       "4  Provide the README content for the section wit...   \n",
       "\n",
       "                                             Context  \\\n",
       "0  Discussions in issues and pull requests:\\n    ...   \n",
       "1  Discussions in issues and pull requests:\\n    ...   \n",
       "2  Discussions in issues and pull requests:\\n    ...   \n",
       "3  # check each category for the minimum number o...   \n",
       "4  Discussions in issues and pull requests:\\n    ...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Explore popular APIs and see them work in Post...   \n",
       "1  | API | Description | Call this API | |:---|:-...   \n",
       "2  | API | Description | Auth | Call this API | |...   \n",
       "3  * [Animals](#animals) * [Anime](#anime) * [Art...   \n",
       "4  <br > <strong>Get Involved</strong> * [Contrib...   \n",
       "\n",
       "                                     Repo Url         Repo  \n",
       "0  https://github.com/public-apis/public-apis  public-apis  \n",
       "1  https://github.com/public-apis/public-apis  public-apis  \n",
       "2  https://github.com/public-apis/public-apis  public-apis  \n",
       "3  https://github.com/public-apis/public-apis  public-apis  \n",
       "4  https://github.com/public-apis/public-apis  public-apis  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=[\"Answer\"], inplace=True)\n",
    "df = df[[\"Question\", \"Context\", \"Answer\", \"Repo Url\", \"Repo\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dc8c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Repo Url</th>\n",
       "      <th>Repo</th>\n",
       "      <th>detect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>Explore popular APIs and see them work in Post...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>| API | Description | Call this API | |:---|:-...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>| API | Description | Auth | Call this API | |...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td># check each category for the minimum number o...</td>\n",
       "      <td>* [Animals](#animals) * [Anime](#anime) * [Art...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provide the README content for the section wit...</td>\n",
       "      <td>Discussions in issues and pull requests:\\n    ...</td>\n",
       "      <td>&lt;br &gt; &lt;strong&gt;Get Involved&lt;/strong&gt; * [Contrib...</td>\n",
       "      <td>https://github.com/public-apis/public-apis</td>\n",
       "      <td>public-apis</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Provide the README content for the section wit...   \n",
       "1  Provide the README content for the section wit...   \n",
       "2  Provide the README content for the section wit...   \n",
       "3  Provide the README content for the section wit...   \n",
       "4  Provide the README content for the section wit...   \n",
       "\n",
       "                                             Context  \\\n",
       "0  Discussions in issues and pull requests:\\n    ...   \n",
       "1  Discussions in issues and pull requests:\\n    ...   \n",
       "2  Discussions in issues and pull requests:\\n    ...   \n",
       "3  # check each category for the minimum number o...   \n",
       "4  Discussions in issues and pull requests:\\n    ...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Explore popular APIs and see them work in Post...   \n",
       "1  | API | Description | Call this API | |:---|:-...   \n",
       "2  | API | Description | Auth | Call this API | |...   \n",
       "3  * [Animals](#animals) * [Anime](#anime) * [Art...   \n",
       "4  <br > <strong>Get Involved</strong> * [Contrib...   \n",
       "\n",
       "                                     Repo Url         Repo detect  \n",
       "0  https://github.com/public-apis/public-apis  public-apis     en  \n",
       "1  https://github.com/public-apis/public-apis  public-apis     en  \n",
       "2  https://github.com/public-apis/public-apis  public-apis     en  \n",
       "3  https://github.com/public-apis/public-apis  public-apis     en  \n",
       "4  https://github.com/public-apis/public-apis  public-apis     en  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "df['detect'] = detect(str(df['Answer']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83daab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12803"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['detect'] == 'en']\n",
    "df = df[[\"Question\", \"Context\", \"Answer\", \"Repo Url\", \"Repo\"]]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2a67e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['explore popular apis and see them work in postman. br p a href div img src .github cs1586 apilayerlogoupdate2022 lj v2 highres.png width 250 alt apilayer logo div a p apilayer is the fastest way to integrate apis into any product. they created this repository to support the community in easily finding public apis. explore their collections on the postman api network .',\n",
       "       ' api description call this api ip stack locate and identify website visitors by ip address img src alt run in postman style width 128px height 32px marketstack free easy to use rest api interface delivering worldwide stock market data in json format img src alt run in postman style width 128px height 32px weatherstack retrieve instant accurate weather information for any location in the world in lightweight json format img src alt run in postman style width 128px height 32px numverify global phone number validation lookup json api img src alt run in postman style width 128px height 32px fixer fixer is a simple and lightweight api for current and historical foreign exchange forex rates. img src alt run in postman style width 128px height 32px br ',\n",
       "       ' api description auth call this api http cat cat for every http status no img src alt run in postman style width 128px height 32px sportmonks football football score schedule news api tv channels stats history display standing e.g. epl la liga apikey img src alt run in postman style width 128px height 32px google maps create customize digital maps based on google maps data apikey img src alt run in postman style width 128px height 32px notion integrate with notion apikey img src alt run in postman style width 128px height 32px plaid connect with user is bank accounts and access transaction data apikey img src alt run in postman style width 128px height 32px br ',\n",
       "       ' animals animals anime anime art design art design authentication authorization authentication authorization blockchain blockchain business business currency exchange currency exchange social social br ',\n",
       "       ' br strong get involved strong contributing guide contributing.md api for this project issues pull requests license license own an api? publish your own run in postman button. br strong more resources strong postman api network free apis dev resources apihouse collective apis div details br br '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"Answer\"] = df[\"Answer\"].apply(clean_text)\n",
    "df[\"Answer\"] = df[\"Answer\"].apply(text_cleaner)\n",
    "df[\"Answer\"] = df[\"Answer\"].apply(clean_emoji)\n",
    "#df[\"Context\"] = df[\"Context\"].apply(text_cleaner)\n",
    "df[\"Answer\"].values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf0e9124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Discussions in issues and pull requests:\\n        - https://github.com/public-apis/public-apis/pull/2409\\n        - https://github.com/public-apis/public-apis/issues/2960 \\n    \"\"\"\\n\\n    code = resp.status_code\\n    server = resp.headers.get(\\'Server\\') or resp.headers.get(\\'server\\')\\n    cloudflare_flags = [\\n        \\'403 Forbidden\\',\\n        \\'cloudflare\\',\\n        \\'Cloudflare\\',\\n        \\'Security check\\',\\n        \\'Please Wait... | Cloudflare\\',\\n        \\'We are checking your browser...\\',\\n        \\'Please stand by, while we are checking your browser...\\',\\n        \\'Checking your browser before accessing\\',\\n        \\'This process is automatic.\\',\\n        \\'Your browser will redirect to your requested content shortly.\\',\\n        \\'Please allow up to 5 seconds\\',\\n        \\'DDoS protection by\\',\\n        \\'Ray ID:\\',\\n        \\'Cloudflare Ray ID:\\',\\n        \\'_cf_chl\\',\\n        \\'_cf_chl_opt\\',\\n        \\'__cf_chl_rt_tk\\',\\n        \\'cf-spinner-please-wait\\',\\n        \\'cf-spinner-redirecting\\'\\n    ]err_msgs = check_entry(0, incorrect_segments)\\n        expected_err_msgs = [\\n            \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\',\\n            \\'(L001) first character of description is not capitalized\\',\\n            \\'(L001) description should not end with .\\',\\n            \\'(L001) auth value is not enclosed with `backticks`\\',\\n            \\'(L001) yes is not a valid Auth option\\',\\n            \\'(L001) yes is not a valid HTTPS option\\',\\n            \\'(L001) yes is not a valid CORS option\\'\\n        ]\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 7)\\n        for err_msg in err_msgs:\\n            with self.subTest():\\n                self.assertIsInstance(err_msg, str)\\n        self.assertEqual(err_msgs, expected_err_msgs)err_msgs = check_title(0, raw_title)\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title syntax should be \"[TITLE](LINK)\"\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_title_with_api_at_the_end_of_the_title(self):\\n        raw_title = \\'[A API](https://www.ex.com)\\'\\n\\n        err_msgs = check_title(0, raw_title)\\n        \\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_description_with_correct_description(self):\\n        desc = \\'This is a fake description\\'\\n\\n        err_msgs = check_description(0, desc)err_msgs = []\\n\\n    title_match = link_re.match(raw_title)\\n\\n    # url should be wrapped in \"[TITLE](LINK)\" Markdown syntax\\n    if not title_match:\\n        err_msg = error_message(line_num, \\'Title syntax should be \"[TITLE](LINK)\"\\')\\n        err_msgs.append(err_msg)\\n    else:\\n        # do not allow \"... API\" in the entry title\\n        title = title_match.group(1)\\n        if title.upper().endswith(\\' API\\'):\\n            err_msg = error_message(line_num, \\'Title should not end with \"... API\". Every entry is an API here!\\')\\n            err_msgs.append(err_msg)\\n\\n    return err_msgs\\n\\n\\ndef check_description(line_num: int, description: str) -> List[str]:\\n\\n    err_msgs = []\\n\\n    first_char = description[0]\\n    if first_char.upper() != first_char:\\n        err_msg = error_message(line_num, \\'first character of description is not capitalized\\')\\n        err_msgs.append(err_msg)',\n",
       "       'Discussions in issues and pull requests:\\n        - https://github.com/public-apis/public-apis/pull/2409\\n        - https://github.com/public-apis/public-apis/issues/2960 \\n    \"\"\"\\n\\n    code = resp.status_code\\n    server = resp.headers.get(\\'Server\\') or resp.headers.get(\\'server\\')\\n    cloudflare_flags = [\\n        \\'403 Forbidden\\',\\n        \\'cloudflare\\',\\n        \\'Cloudflare\\',\\n        \\'Security check\\',\\n        \\'Please Wait... | Cloudflare\\',\\n        \\'We are checking your browser...\\',\\n        \\'Please stand by, while we are checking your browser...\\',\\n        \\'Checking your browser before accessing\\',\\n        \\'This process is automatic.\\',\\n        \\'Your browser will redirect to your requested content shortly.\\',\\n        \\'Please allow up to 5 seconds\\',\\n        \\'DDoS protection by\\',\\n        \\'Ray ID:\\',\\n        \\'Cloudflare Ray ID:\\',\\n        \\'_cf_chl\\',\\n        \\'_cf_chl_opt\\',\\n        \\'__cf_chl_rt_tk\\',\\n        \\'cf-spinner-please-wait\\',\\n        \\'cf-spinner-redirecting\\'\\n    ]err_msgs = check_title(0, raw_title)\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title syntax should be \"[TITLE](LINK)\"\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_title_with_api_at_the_end_of_the_title(self):\\n        raw_title = \\'[A API](https://www.ex.com)\\'\\n\\n        err_msgs = check_title(0, raw_title)\\n        \\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_description_with_correct_description(self):\\n        desc = \\'This is a fake description\\'\\n\\n        err_msgs = check_description(0, desc)err_msgs = []\\n\\n    title_match = link_re.match(raw_title)\\n\\n    # url should be wrapped in \"[TITLE](LINK)\" Markdown syntax\\n    if not title_match:\\n        err_msg = error_message(line_num, \\'Title syntax should be \"[TITLE](LINK)\"\\')\\n        err_msgs.append(err_msg)\\n    else:\\n        # do not allow \"... API\" in the entry title\\n        title = title_match.group(1)\\n        if title.upper().endswith(\\' API\\'):\\n            err_msg = error_message(line_num, \\'Title should not end with \"... API\". Every entry is an API here!\\')\\n            err_msgs.append(err_msg)\\n\\n    return err_msgs\\n\\n\\ndef check_description(line_num: int, description: str) -> List[str]:\\n\\n    err_msgs = []\\n\\n    first_char = description[0]\\n    if first_char.upper() != first_char:\\n        err_msg = error_message(line_num, \\'first character of description is not capitalized\\')\\n        err_msgs.append(err_msg)err_msgs = check_entry(0, incorrect_segments)\\n        expected_err_msgs = [\\n            \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\',\\n            \\'(L001) first character of description is not capitalized\\',\\n            \\'(L001) description should not end with .\\',\\n            \\'(L001) auth value is not enclosed with `backticks`\\',\\n            \\'(L001) yes is not a valid Auth option\\',\\n            \\'(L001) yes is not a valid HTTPS option\\',\\n            \\'(L001) yes is not a valid CORS option\\'\\n        ]\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 7)\\n        for err_msg in err_msgs:\\n            with self.subTest():\\n                self.assertIsInstance(err_msg, str)\\n        self.assertEqual(err_msgs, expected_err_msgs)',\n",
       "       'Discussions in issues and pull requests:\\n        - https://github.com/public-apis/public-apis/pull/2409\\n        - https://github.com/public-apis/public-apis/issues/2960 \\n    \"\"\"\\n\\n    code = resp.status_code\\n    server = resp.headers.get(\\'Server\\') or resp.headers.get(\\'server\\')\\n    cloudflare_flags = [\\n        \\'403 Forbidden\\',\\n        \\'cloudflare\\',\\n        \\'Cloudflare\\',\\n        \\'Security check\\',\\n        \\'Please Wait... | Cloudflare\\',\\n        \\'We are checking your browser...\\',\\n        \\'Please stand by, while we are checking your browser...\\',\\n        \\'Checking your browser before accessing\\',\\n        \\'This process is automatic.\\',\\n        \\'Your browser will redirect to your requested content shortly.\\',\\n        \\'Please allow up to 5 seconds\\',\\n        \\'DDoS protection by\\',\\n        \\'Ray ID:\\',\\n        \\'Cloudflare Ray ID:\\',\\n        \\'_cf_chl\\',\\n        \\'_cf_chl_opt\\',\\n        \\'__cf_chl_rt_tk\\',\\n        \\'cf-spinner-please-wait\\',\\n        \\'cf-spinner-redirecting\\'\\n    ]err_msgs = []\\n\\n    title_match = link_re.match(raw_title)\\n\\n    # url should be wrapped in \"[TITLE](LINK)\" Markdown syntax\\n    if not title_match:\\n        err_msg = error_message(line_num, \\'Title syntax should be \"[TITLE](LINK)\"\\')\\n        err_msgs.append(err_msg)\\n    else:\\n        # do not allow \"... API\" in the entry title\\n        title = title_match.group(1)\\n        if title.upper().endswith(\\' API\\'):\\n            err_msg = error_message(line_num, \\'Title should not end with \"... API\". Every entry is an API here!\\')\\n            err_msgs.append(err_msg)\\n\\n    return err_msgs\\n\\n\\ndef check_description(line_num: int, description: str) -> List[str]:\\n\\n    err_msgs = []\\n\\n    first_char = description[0]\\n    if first_char.upper() != first_char:\\n        err_msg = error_message(line_num, \\'first character of description is not capitalized\\')\\n        err_msgs.append(err_msg)num_segments = 5\\nmin_entries_per_category = 3\\nmax_description_length = 100\\n\\nanchor_re = re.compile(anchor + \\'\\\\s(.+)\\')\\ncategory_title_in_index_re = re.compile(\\'\\\\*\\\\s\\\\[(.*)\\\\]\\')\\nlink_re = re.compile(\\'\\\\[(.+)\\\\]\\\\((http.*)\\\\)\\')\\n\\n# Type aliases\\nAPIList = List[str]\\nCategories = Dict[str, APIList]\\nCategoriesLineNumber = Dict[str, int]\\n\\n\\ndef error_message(line_number: int, message: str) -> str:\\n    line = line_number + 1\\n    return f\\'(L{line:03d}) {message}\\'\\n\\n\\ndef get_categories_content(contents: List[str]) -> Tuple[Categories, CategoriesLineNumber]:\\n\\n    categories = {}\\n    category_line_num = {}\\n\\n    for line_num, line_content in enumerate(contents):\\n\\n        if line_content.startswith(anchor):\\n            category = line_content.split(anchor)[1].strip()\\n            categories[category] = []\\n            category_line_num[category] = line_num\\n            continue\\n\\n        if not line_content.startswith(\\'|\\') or line_content.startswith(\\'|---\\'):\\n            continueerr_msgs = check_title(0, raw_title)\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title syntax should be \"[TITLE](LINK)\"\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_title_with_api_at_the_end_of_the_title(self):\\n        raw_title = \\'[A API](https://www.ex.com)\\'\\n\\n        err_msgs = check_title(0, raw_title)\\n        \\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_description_with_correct_description(self):\\n        desc = \\'This is a fake description\\'\\n\\n        err_msgs = check_description(0, desc)',\n",
       "       \"# check each category for the minimum number of entries\\n        if line_content.startswith(anchor):\\n            category_match = anchor_re.match(line_content)\\n            if category_match:\\n                if category_match.group(1) not in category_title_in_index:\\n                    err_msg = error_message(line_num, f'category header ({category_match.group(1)}) not added to Index section')\\n                    err_msgs.append(err_msg)\\n            else:\\n                err_msg = error_message(line_num, 'category header is not formatted correctly')\\n                err_msgs.append(err_msg)\\n\\n            if num_in_category < min_entries_per_category:\\n                err_msg = error_message(category_line, f'{category} category does not have the minimum {min_entries_per_category} entries (only has {num_in_category})')\\n                err_msgs.append(err_msg)num_segments = 5\\nmin_entries_per_category = 3\\nmax_description_length = 100\\n\\nanchor_re = re.compile(anchor + '\\\\s(.+)')\\ncategory_title_in_index_re = re.compile('\\\\*\\\\s\\\\[(.*)\\\\]')\\nlink_re = re.compile('\\\\[(.+)\\\\]\\\\((http.*)\\\\)')\\n\\n# Type aliases\\nAPIList = List[str]\\nCategories = Dict[str, APIList]\\nCategoriesLineNumber = Dict[str, int]\\n\\n\\ndef error_message(line_number: int, message: str) -> str:\\n    line = line_number + 1\\n    return f'(L{line:03d}) {message}'\\n\\n\\ndef get_categories_content(contents: List[str]) -> Tuple[Categories, CategoriesLineNumber]:\\n\\n    categories = {}\\n    category_line_num = {}\\n\\n    for line_num, line_content in enumerate(contents):\\n\\n        if line_content.startswith(anchor):\\n            category = line_content.split(anchor)[1].strip()\\n            categories[category] = []\\n            category_line_num[category] = line_num\\n            continue\\n\\n        if not line_content.startswith('|') or line_content.startswith('|---'):\\n            continueraw_title = [\\n            raw_content.strip() for raw_content in line_content.split('|')[1:-1]\\n        ][0]\\n\\n        title_match = link_re.match(raw_title)\\n        if title_match:\\n                title = title_match.group(1).upper()\\n                categories[category].append(title)\\n\\n    return (categories, category_line_num)\\n\\n\\ndef check_alphabetical_order(lines: List[str]) -> List[str]:\\n\\n    err_msgs = []\\n\\n    categories, category_line_num = get_categories_content(contents=lines)\\n\\n    for category, api_list in categories.items():\\n        if sorted(api_list) != api_list:\\n            err_msg = error_message(\\n                category_line_num[category], \\n                f'{category} category is not alphabetical order'\\n            )\\n            err_msgs.append(err_msg)\\n    \\n    return err_msgs\\n\\n\\ndef check_title(line_num: int, raw_title: str) -> List[str]:\\n\\n    err_msgs = []\\n\\n    title_match = link_re.match(raw_title)err_msgs = [\\n        *title_err_msgs,\\n        *desc_err_msgs,\\n        *auth_err_msgs,\\n        *https_err_msgs,\\n        *cors_err_msgs\\n    ]\\n\\n    return err_msgs\\n\\n\\ndef check_file_format(lines: List[str]) -> List[str]:\\n\\n    err_msgs = []\\n    category_title_in_index = []\\n\\n    alphabetical_err_msgs = check_alphabetical_order(lines)\\n    err_msgs.extend(alphabetical_err_msgs)\\n\\n    num_in_category = min_entries_per_category + 1\\n    category = ''\\n    category_line = 0\\n\\n    for line_num, line_content in enumerate(lines):\\n\\n        category_title_match = category_title_in_index_re.match(line_content)\\n        if category_title_match:\\n            category_title_in_index.append(category_title_match.group(1))\",\n",
       "       'Discussions in issues and pull requests:\\n        - https://github.com/public-apis/public-apis/pull/2409\\n        - https://github.com/public-apis/public-apis/issues/2960 \\n    \"\"\"\\n\\n    code = resp.status_code\\n    server = resp.headers.get(\\'Server\\') or resp.headers.get(\\'server\\')\\n    cloudflare_flags = [\\n        \\'403 Forbidden\\',\\n        \\'cloudflare\\',\\n        \\'Cloudflare\\',\\n        \\'Security check\\',\\n        \\'Please Wait... | Cloudflare\\',\\n        \\'We are checking your browser...\\',\\n        \\'Please stand by, while we are checking your browser...\\',\\n        \\'Checking your browser before accessing\\',\\n        \\'This process is automatic.\\',\\n        \\'Your browser will redirect to your requested content shortly.\\',\\n        \\'Please allow up to 5 seconds\\',\\n        \\'DDoS protection by\\',\\n        \\'Ray ID:\\',\\n        \\'Cloudflare Ray ID:\\',\\n        \\'_cf_chl\\',\\n        \\'_cf_chl_opt\\',\\n        \\'__cf_chl_rt_tk\\',\\n        \\'cf-spinner-please-wait\\',\\n        \\'cf-spinner-redirecting\\'\\n    ]err_msgs = []\\n\\n    title_match = link_re.match(raw_title)\\n\\n    # url should be wrapped in \"[TITLE](LINK)\" Markdown syntax\\n    if not title_match:\\n        err_msg = error_message(line_num, \\'Title syntax should be \"[TITLE](LINK)\"\\')\\n        err_msgs.append(err_msg)\\n    else:\\n        # do not allow \"... API\" in the entry title\\n        title = title_match.group(1)\\n        if title.upper().endswith(\\' API\\'):\\n            err_msg = error_message(line_num, \\'Title should not end with \"... API\". Every entry is an API here!\\')\\n            err_msgs.append(err_msg)\\n\\n    return err_msgs\\n\\n\\ndef check_description(line_num: int, description: str) -> List[str]:\\n\\n    err_msgs = []\\n\\n    first_char = description[0]\\n    if first_char.upper() != first_char:\\n        err_msg = error_message(line_num, \\'first character of description is not capitalized\\')\\n        err_msgs.append(err_msg)err_msgs = check_title(0, raw_title)\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title syntax should be \"[TITLE](LINK)\"\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_title_with_api_at_the_end_of_the_title(self):\\n        raw_title = \\'[A API](https://www.ex.com)\\'\\n\\n        err_msgs = check_title(0, raw_title)\\n        \\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 1)\\n        \\n        err_msg = err_msgs[0]\\n        expected_err_msg = \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\'\\n\\n        self.assertEqual(err_msg, expected_err_msg)\\n\\n    def test_check_description_with_correct_description(self):\\n        desc = \\'This is a fake description\\'\\n\\n        err_msgs = check_description(0, desc)err_msgs = check_entry(0, incorrect_segments)\\n        expected_err_msgs = [\\n            \\'(L001) Title should not end with \"... API\". Every entry is an API here!\\',\\n            \\'(L001) first character of description is not capitalized\\',\\n            \\'(L001) description should not end with .\\',\\n            \\'(L001) auth value is not enclosed with `backticks`\\',\\n            \\'(L001) yes is not a valid Auth option\\',\\n            \\'(L001) yes is not a valid HTTPS option\\',\\n            \\'(L001) yes is not a valid CORS option\\'\\n        ]\\n\\n        self.assertIsInstance(err_msgs, list)\\n        self.assertEqual(len(err_msgs), 7)\\n        for err_msg in err_msgs:\\n            with self.subTest():\\n                self.assertIsInstance(err_msg, str)\\n        self.assertEqual(err_msgs, expected_err_msgs)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Context\"].values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56da770",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['allennlp', 'autojump', 'typer', 'spotify-downloader', 'spleeter', 'python-fire', 'numpy-ml', 'magenta'] \n",
    "   \n",
    "# selecting rows based on condition \n",
    "df = df[df['Repo'].isin(options)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Answer\"].values[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"scripts/readme_qa.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985ccd1",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee64205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# from torchmetrics.text.bert import BERTScore\n",
    "import bert_score\n",
    "import re\n",
    "\n",
    "with open(\"README_LLAMA2_7B_CHAT_GPTQ.md\", 'r', encoding='utf-8') as f:\n",
    "    pred = f.read()\n",
    "with open(\"spleeter/README.md\", 'r', encoding='utf-8') as f:\n",
    "    target = f.read()\n",
    "\n",
    "pred = re.sub(r' +', ' ', pred)\n",
    "target = re.sub(r' +', ' ', target)\n",
    "P, R, F1 = bert_score.score([pred], [target], lang='en', model_type='roberta-large', verbose=True)\n",
    "print(P,R,F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02cebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download the required NLTK data\n",
    "# nltk.download('punkt')\n",
    "\n",
    "pred = \"\"\n",
    "target = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Llama-2-7b-Chat-GPTQ\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def calculate_bleu(reference, candidate):\n",
    "    reference_tokens = tokenizer.tokenize(reference)\n",
    "    candidate_tokens = tokenizer.tokenize(candidate)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\n",
    "\n",
    "bleu_score = calculate_bleu(target, pred)\n",
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f3f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymarkdown.api import PyMarkdownApi\n",
    "\n",
    "source_path = \"README_LLAMA2_7B_CHAT_GPTQ.md\"\n",
    "errors = PyMarkdownApi().scan_path(source_path)\n",
    "print(len(errors.scan_failures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26757139",
   "metadata": {},
   "source": [
    "# Markdown to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93058bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install markdown-to-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown_to_json\n",
    "md_file_path = \"/content/README.md\"\n",
    "with open(md_file_path, 'r', encoding='utf-8') as file:\n",
    "    md_content = file.read()\n",
    "\n",
    "# The simple way:\n",
    "dictified = markdown_to_json.dictify(md_content)\n",
    "dictified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictified['Try Public APIs for free']['Index']['Anime'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
